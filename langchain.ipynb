{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702e5eb-235d-4999-8d31-3f4a5194f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='baa96daf-e4e6-488c-9d29-d3151d458508'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 140, 'total_tokens': 228, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cpfld5YOT0OYSkpCDDcC7VtWZJdvO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b4782-da6c-7aa3-b663-578782de8a03-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_VFUR9G6oBl0kdFB0wrsZPb3X', 'type': 'tool_call'}], usage_metadata={'input_tokens': 140, 'output_tokens': 88, 'total_tokens': 228, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='ad40abc3-8a17-4ee9-8ad1-92b8c84f35f1', tool_call_id='call_VFUR9G6oBl0kdFB0wrsZPb3X'), AIMessage(content='According to the weather service: \"It\\'s always sunny in San Francisco!\"\\n\\nWould you like the current temperature, an hourly forecast, or the next few days\\' outlook?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 234, 'prompt_tokens': 176, 'total_tokens': 410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cpflgq5GdX7XMMEfqDWv6sCTy97kx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b4782-e4b0-7b41-932e-bd8616645ba0-0', usage_metadata={'input_tokens': 176, 'output_tokens': 234, 'total_tokens': 410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\",\n",
    "                   api_key=\"YOUR-API-KEY\", \n",
    "                   temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e704dc-1276-4272-9580-abbc6c67cf3d",
   "metadata": {},
   "source": [
    "# Build a real world agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55319c-d8a0-467d-848e-cf2eef9aa6ea",
   "metadata": {},
   "source": [
    "The system prompt defines your agent’s role and behavior. Keep it specific and actionable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a62cc4-bb05-4051-942c-5e801b970adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc03c55-a1a9-4cb0-9793-c86d70b6cba4",
   "metadata": {},
   "source": [
    "Tools let a model interact with external systems by calling functions you define. Tools can depend on runtime context and also interact with agent memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bcb096b-4ef4-42e1-a9d7-78a861f954ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c6346-8a4f-43a4-8b74-a8e8ae9235fe",
   "metadata": {},
   "source": [
    "set up languange model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375889ae-c7d0-4f7f-8ec9-6873dbea3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model = init_chat_model(\n",
    "#     \"claude-sonnet-4-5-20250929\",\n",
    "#     temperature=0.5,\n",
    "#     timeout=10,\n",
    "#     max_tokens=1000\n",
    "# )\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\",\n",
    "        api_key=\"YOUR-API-KEY\", \n",
    "        temperature=0.5,\n",
    "        timeout=60,\n",
    "        max_tokens=1000         \n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee575a-1d5b-4d58-a9f9-3d64f3278446",
   "metadata": {},
   "source": [
    "Define Response Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd307944-e6ba-43ea-b39f-1d4b082430d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75737cee-5dad-4fd2-b1e4-bddcc1fb7227",
   "metadata": {},
   "source": [
    "Add memory to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a011acf8-4d3b-4e93-9e10-4b6c600b3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1083a7-8d2a-4aa1-be54-4269e0ad7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a969e0-37a6-462c-a19a-b6471fb526f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3c533-3c7d-4e72-8967-65ad4ddb868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_tool],\n",
    "    response_format=ToolStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \n",
    "                  \"content\": \"Extract contact info from: John Doe, \n",
    "                  john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c8f4c-fa98-4ab4-a717-ee42c2d1c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf6b04a-3503-4fb4-9a94-629fb714cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic System Prompt\n",
    "# !pip install langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428d8329-ac01-4f29-bf17-b7e99fe570d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from langchain.tools.tavily_search import TavilySearchResults\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# web_search = TavilySearchResults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f989c08-b6f5-48d4-91bb-3e32242f540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef94f3be-ea85-4426-b5ae-978f467a8e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain machine learning', additional_kwargs={}, response_metadata={}, id='66f29c35-d2f8-43ff-bfde-a009ec16d0d5'),\n",
       "  AIMessage(content='Machine learning (ML) is a way for computers to learn patterns from data so they can make predictions or decisions without being explicitly programmed for each specific task.\\n\\nShort analogy\\n- Teaching a child: instead of writing rules for every possible situation, you show examples (pictures of cats and dogs). Over time the child learns to recognize a cat from patterns in the examples. ML does the same with data.\\n\\nHow it works (high level)\\n1. Collect data: examples that show the input and (often) the desired output.\\n2. Choose a model: a flexible program structure that can represent relationships in the data (simple line, tree, neural network, etc.).\\n3. Train the model: adjust the model’s internal settings so its outputs match the examples as well as possible.\\n4. Evaluate: test the model on new data it hasn’t seen to check how well it generalizes.\\n5. Use and refine: deploy the model for real tasks and improve it by collecting more/better data or changing the model.\\n\\nMain types of machine learning\\n- Supervised learning: learn from labeled examples (inputs paired with correct outputs). Used for classification (spam vs. not spam) and regression (predict house prices).\\n- Unsupervised learning: find structure in unlabeled data (clustering, dimensionality reduction). Used for customer segmentation or finding patterns.\\n- Reinforcement learning: an agent learns by trial and error, getting rewards or penalties (used in game playing, robotics).\\n\\nKey concepts (simple)\\n- Features: the inputs or characteristics you use to teach the model (age, height, pixels).\\n- Labels/targets: the correct answers you want the model to predict (cat/dog, price).\\n- Training: the process of learning from data.\\n- Loss function: a way to measure how wrong the model is; training minimizes this.\\n- Generalization: how well the model performs on new, unseen data.\\n- Overfitting: the model memorizes the training data and fails on new data.\\n- Underfitting: the model is too simple and can’t capture important patterns.\\n\\nCommon algorithms (brief)\\n- Linear regression — predicts numbers with a line.\\n- Logistic regression / decision trees — simple classification.\\n- k-means — basic clustering.\\n- Random forests / gradient boosting — powerful tree-based methods.\\n- Neural networks / deep learning — flexible models for images, text, audio.\\n\\nReal-world examples\\n- Email spam filters, product recommendations, voice assistants, medical image diagnosis, fraud detection, self-driving car perception.\\n\\nLimitations and risks\\n- ML models depend on the quality and representativeness of data; biased data -> biased predictions.\\n- They can be sensitive to changes in real-world conditions.\\n- Some models are hard to interpret — “black box” behavior.\\n- Privacy and ethical concerns (surveillance, unfair decisions) must be considered.\\n\\nHow to get started (if you want to learn)\\n- Learn basics of Python and libraries like scikit-learn, pandas, TensorFlow or PyTorch.\\n- Try small projects: classifying images, predicting house prices, clustering customers.\\n- Study evaluation (train/test split, cross-validation) and basic statistics.\\n\\nIf you want, I can give a simple example, recommend beginner tutorials, or explain any part in more detail. Which area interests you most?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 868, 'prompt_tokens': 26, 'total_tokens': 894, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CpjYNqJlJIq8s6Vs0bNYEnKkRv1VR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b4860-efe5-77f0-b274-f81d5563160d-0', usage_metadata={'input_tokens': 26, 'output_tokens': 868, 'total_tokens': 894, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcb267c-81dc-4949-9178-6007e66a5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32c6243-d9fc-43b7-9832-69c48e607488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd208c3-20c6-4a18-9288-f52e6d7b6634",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with '.venv (Python 3.10.19)' requires the jupyter and notebook package.\n",
      "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # tools=[search_tool],\n",
    "    response_format=ToolStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e427ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "export OPENAI_API_KEY=\"YOUR-API-KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d3b94-5ecb-4651-9f17-a3cfb218cca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
