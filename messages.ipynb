{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cd2079",
   "metadata": {},
   "source": [
    "Messages - Fundamental unit of context for models in LangChain. They represent the input and output of a models, carrying information about the role of the user, the content of the message, and additional metadata.\n",
    "\n",
    "- Role: Identify the role of the speaker. Common roles include 'user', 'assistant', 'system', 'tool', and 'human'.\n",
    "- Content: The actual content of the message. \n",
    "- Metadata: Additional information such as the source of the message, the time it was sent, token usage, or any other relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b08567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you. How can I help you with your musical journey today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a musical teacher.\"),\n",
    "    HumanMessage(content=\"Hello, how are you?\"),\n",
    "    AIMessage(content=\"I'm good, thanks! How about you?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2c07e",
   "metadata": {},
   "source": [
    "# Detailed Info to LLM through System Message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fee985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! I‚Äôll explain as if you‚Äôre new to the topic:\n",
      "\n",
      "### What is a Tree Model?  \n",
      "A **tree model** in data science is a way for a computer to make decisions step by step, just like you might when solving a problem or picking what to eat for dinner.\n",
      "\n",
      "### How Does It Work?  \n",
      "Imagine a game of \"20 Questions.\" You start by asking big, general questions to narrow things down‚Äî‚ÄúIs it an animal?‚Äù Depending on the answer (yes or no), you ask more specific questions, until you reach your answer.\n",
      "\n",
      "A tree model works similarly:\n",
      "\n",
      "1. **Asking Questions:**  \n",
      "   The model starts at the top‚Äîcalled the *root*‚Äîand asks a question about your data. For example, for deciding if someone will buy a product, it might ask, \"Is the person over 30 years old?\"\n",
      "\n",
      "2. **Splitting Paths:**  \n",
      "   If the answer is YES, you go down one branch. If NO, you go down the other.  \n",
      "   Each path leads to another question (another *branch*), getting more detailed each time.\n",
      "\n",
      "3. **Getting Answers:**  \n",
      "   Eventually, the paths end at a leaf, which gives the model‚Äôs answer or prediction (e.g., ‚ÄúWill buy‚Äù or ‚ÄúWon‚Äôt buy‚Äù).\n",
      "\n",
      "### A Simple Example:  \n",
      "Let's say we want to predict if a person will play tennis.\n",
      "\n",
      "- **Root:** ‚ÄúIs it sunny?‚Äù\n",
      "  - **Yes:** ‚ÄúIs it humid?‚Äù\n",
      "      - **Yes:** ‚ÄúDon‚Äôt play.‚Äù\n",
      "      - **No:** ‚ÄúPlay!‚Äù\n",
      "  - **No:** ‚ÄúPlay!‚Äù\n",
      "\n",
      "The model works its way through the tree, asking one question at a time, until it makes its decision.\n",
      "\n",
      "### Why Use Tree Models?  \n",
      "- They‚Äôre easy to understand‚Äîlike a flowchart.\n",
      "- They can handle both numbers and categories.\n",
      "- They‚Äôre good at many kinds of prediction problems.\n",
      "\n",
      "**In short:**  \n",
      "A tree model helps computers make decisions by asking a chain of yes/no questions until they reach an answer‚Äîjust like a game of questions and answers.\n",
      "\n",
      "Let me know if you‚Äôd like to see a visual example or want to know how it works ‚Äúunder the hood‚Äù!\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a Senior Data Scientist with expertise in GenAI. Always provide answer with proper reasoning.\n",
    "Understand your audience and answer accordingly. For a non-technical user, answer in the lay man language. \n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"how does tree model works?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef489ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Alice! How can I help you today? üòä'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With metadata\n",
    "\n",
    "humanmsg = HumanMessage(\n",
    "    content=\"Hello\",\n",
    "    name = \"Alice\",\n",
    "    id = \"msg_123\"\n",
    ")\n",
    "\n",
    "response = model.invoke([humanmsg])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93416fb9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
